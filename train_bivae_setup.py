import pickle
import os
import cornac
from local_config import DATA_DIR, VOCAB_PATH


def load_and_prep_data():
    print("ğŸ”„ Äang load dá»¯ liá»‡u tá»« há»‡ thá»‘ng cÅ©...")

    # 1. Load Vocabulary (Äá»ƒ Ä‘áº£m báº£o ID khá»›p nhau)
    # ChÃºng ta cáº§n item2idx Ä‘á»ƒ biáº¿t há»‡ thá»‘ng hiá»‡n táº¡i map MovieID nÃ o sang Index nÃ o
    with open(VOCAB_PATH, "rb") as f:
        vocab = pickle.load(f)

    # idx2item: map tá»« Internal Index (0,1,2...) -> Movie ID gá»‘c (1, 2, 94...)
    # item2idx: map tá»« Movie ID gá»‘c -> Internal Index
    # idx2item = vocab["idx2item"]
    # item2idx = vocab["item2idx"]
    num_items = vocab["num_items"]

    print(f"âœ… ÄÃ£ load Vocab: {num_items} items.")

    # 2. Load Training Data (Dá»¯ liá»‡u chuá»—i NextItNet)
    train_path = os.path.join(DATA_DIR, "train.pkl")
    with open(train_path, "rb") as f:
        train_data = pickle.load(f)

    # train_data cÃ³ dáº¡ng {'input_seqs': [[1, 2], ...], 'target_items': [3, ...]}
    # ChÃºng ta cáº§n chuyá»ƒn nÃ³ thÃ nh list cÃ¡c bá»™ ba (User_ID, Item_Index, Rating)
    # VÃ¬ NextItNet khÃ´ng lÆ°u UserID trong file pkl (nÃ³ chá»‰ lÆ°u chuá»—i),
    # ta sáº½ giáº£ Ä‘á»‹nh má»—i chuá»—i tÆ°Æ¡ng á»©ng vá»›i má»™t User Index áº£o hoáº·c láº¥y tá»« session.
    # Äá»‚ ÄÆ N GIáº¢N VÃ€ HIá»†U QUáº¢ CHO BIVAE:
    # Ta coi má»—i dÃ²ng trong input_seqs lÃ  má»™t user áº©n danh.

    print("ğŸ”„ Äang chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u chuá»—i sang dáº¡ng User-Item...")

    uir_tuples = []
    # Set Ä‘á»ƒ trÃ¡nh duplicate (User A xem phim B nhiá»u láº§n chá»‰ tÃ­nh lÃ  1 tÆ°Æ¡ng tÃ¡c tÃ­ch cá»±c)
    seen_interactions = set()

    for user_idx, seq in enumerate(train_data["input_seqs"]):
        # Láº¥y target item (phim tiáº¿p theo user Ä‘Ã£ xem)
        target = train_data["target_items"][user_idx]

        # ThÃªm cÃ¡c phim trong lá»‹ch sá»­
        for item_idx in seq:
            if item_idx != 0:  # Bá» qua padding (sá»‘ 0)
                if (user_idx, item_idx) not in seen_interactions:
                    uir_tuples.append((str(user_idx), item_idx, 1.0))
                    seen_interactions.add((user_idx, item_idx))

        # ThÃªm target item (cÅ©ng lÃ  phim user Ä‘Ã£ xem/thÃ­ch)
        if (user_idx, target) not in seen_interactions:
            uir_tuples.append((str(user_idx), target, 1.0))
            seen_interactions.add((user_idx, target))

    print(f"âœ… ÄÃ£ táº¡o {len(uir_tuples)} tÆ°Æ¡ng tÃ¡c (User-Item).")

    # # 3. Táº¡o Cornac Dataset vá»›i Global Item IDs cá»‘ Ä‘á»‹nh
    # # ÄÃ¢y lÃ  bÆ°á»›c QUAN TRá»ŒNG NHáº¤T: Ã‰p Cornac dÃ¹ng khÃ´ng gian ID giá»‘ng há»‡t NextItNet

    # # Táº¡o danh sÃ¡ch táº¥t cáº£ item indices cÃ³ thá»ƒ cÃ³ (tá»« 0 Ä‘áº¿n num_items - 1)
    # # Äiá»u nÃ y Ä‘áº£m báº£o ma tráº­n cá»§a Cornac sáº½ cÃ³ kÃ­ch thÆ°á»›c chÃ­nh xÃ¡c nhÆ° NextItNet
    # all_item_indices = list(range(num_items))

    # # Cornac Dataset
    dataset = cornac.data.Dataset.from_uir(
        data=uir_tuples,
        seed=42,
        # Ã‰p buá»™c dÃ¹ng danh sÃ¡ch item nÃ y, khÃ´ng cho Cornac tá»± sinh ID má»›i
        # item_ids=all_item_indices
        # user_set=user_set,
        # item_set=item_set,
    )

    print(
        f"âœ… Cornac Dataset Info: Users={dataset.num_users}, Items={dataset.num_items}"
    )

    print(
        f"âœ… Cornac Dataset Info: Users={dataset.num_users}, Items={dataset.num_items}"
    )

    if dataset.num_items != num_items:
        print(
            f"âš ï¸ Cáº¢NH BÃO: Sá»‘ lÆ°á»£ng item khÃ´ng khá»›p! (Cornac: {dataset.num_items} vs Vocab: {num_items})"
        )
        # Náº¿u lá»‡ch nháº¹ do padding index 0, cÃ³ thá»ƒ cháº¥p nháº­n Ä‘Æ°á»£c, nhÆ°ng cáº§n lÆ°u Ã½.

    return dataset


if __name__ == "__main__":
    load_and_prep_data()
